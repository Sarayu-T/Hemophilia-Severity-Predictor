{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type    Effect  cDNA  Amino acid (HGVS)  Amino acid (Legacy)  \\\n",
      "0  Point  Missense   216                 72                   53   \n",
      "1  Point  Missense     1                  1                  -19   \n",
      "2  Point  Missense     1                  1                  -19   \n",
      "3  Point  Missense     1                  1                  -19   \n",
      "4  Point  Missense     1                  1                  -19   \n",
      "\n",
      "           Domain Locationingene Severity nitroBaseBef nitroBaseAft  pos  \\\n",
      "0              A1         Exon 2     Mild            A            C   72   \n",
      "1  Signal Peptide         Exon 1   Severe            A            G    1   \n",
      "2  Signal Peptide         Exon 1   Severe            A            G    1   \n",
      "3  Signal Peptide         Exon 1   Severe            A            G    1   \n",
      "4  Signal Peptide         Exon 1   Severe            A            G    1   \n",
      "\n",
      "   wrf_encoded  new_encoded    p  f_encoded  l_encoded seqBefore seqAfter  \n",
      "0            2            2  216          0          1       GAA      GAC  \n",
      "1            9           17    1          0          2       ATG      GTG  \n",
      "2            9           17    1          0          2       ATG      GTG  \n",
      "3            9           17    1          0          2       ATG      GTG  \n",
      "4            9           17    1          0          2       ATG      GTG  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'D:\\Github portfolio\\Hemophilia\\Hemophilia-Severity-Predictor\\RNN_dataset_creation\\RNN_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'severity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'severity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m seq_before \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseqBefore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m seq_after \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseqAfter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 4\u001b[0m severity \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseverity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Encode the sequences (you might need to tokenize them properly based on your data)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# For simplicity, here we assume each character represents an element in the sequence\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_sequence\u001b[39m(seq):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'severity'"
     ]
    }
   ],
   "source": [
    "# Assuming 'seqBefore', 'seqAfter', and 'severity' are the relevant columns\n",
    "seq_before = data['seqBefore'].values\n",
    "seq_after = data['seqAfter'].values\n",
    "severity = data['Severity'].values\n",
    "\n",
    "# Encode the sequences (you might need to tokenize them properly based on your data)\n",
    "# For simplicity, here we assume each character represents an element in the sequence\n",
    "def encode_sequence(seq):\n",
    "    return [ord(char) for char in seq]\n",
    "\n",
    "seq_before_encoded = [encode_sequence(seq) for seq in seq_before]\n",
    "seq_after_encoded = [encode_sequence(seq) for seq in seq_after]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_len = max(max(len(seq) for seq in seq_before_encoded), max(len(seq) for seq in seq_after_encoded))\n",
    "seq_before_padded = pad_sequences(seq_before_encoded, maxlen=max_len, padding='post')\n",
    "seq_after_padded = pad_sequences(seq_after_encoded, maxlen=max_len, padding='post')\n",
    "\n",
    "# Encode the severity labels\n",
    "label_encoder = LabelEncoder()\n",
    "severity_encoded = label_encoder.fit_transform(severity)\n",
    "severity_encoded = np.expand_dims(severity_encoded, axis=-1)\n",
    "\n",
    "# One-hot encode the severity labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "severity_one_hot = one_hot_encoder.fit_transform(severity_encoded)\n",
    "\n",
    "# Combine the sequences (you can also choose to use them separately)\n",
    "combined_sequences = np.concatenate((seq_before_padded, seq_after_padded), axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_sequences, severity_one_hot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=256, output_dim=64, input_length=combined_sequences.shape[1]))\n",
    "model.add(SimpleRNN(units=128, return_sequences=False))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model\n",
    "model.save('rnn_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
