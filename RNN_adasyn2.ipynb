{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cDNA</th>\n",
       "      <th>Amino acid (HGVS)</th>\n",
       "      <th>Amino acid (Legacy)</th>\n",
       "      <th>pos</th>\n",
       "      <th>Type</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Sequence Context</th>\n",
       "      <th>Original AA</th>\n",
       "      <th>New AA</th>\n",
       "      <th>AminoBefore</th>\n",
       "      <th>AminoAfter</th>\n",
       "      <th>Locationingene</th>\n",
       "      <th>nitroBaseBef</th>\n",
       "      <th>nitroBaseAft</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.411869</td>\n",
       "      <td>-1.412448</td>\n",
       "      <td>-1.412429</td>\n",
       "      <td>2.224128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.499705</td>\n",
       "      <td>-1.499467</td>\n",
       "      <td>-1.500672</td>\n",
       "      <td>-0.958553</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.499705</td>\n",
       "      <td>-1.499467</td>\n",
       "      <td>-1.500672</td>\n",
       "      <td>-0.958553</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.499705</td>\n",
       "      <td>-1.499467</td>\n",
       "      <td>-1.500672</td>\n",
       "      <td>-0.958553</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.499705</td>\n",
       "      <td>-1.499467</td>\n",
       "      <td>-1.500672</td>\n",
       "      <td>-0.958553</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cDNA  Amino acid (HGVS)  Amino acid (Legacy)       pos  Type  Domain  \\\n",
       "0 -1.411869          -1.412448            -1.412429  2.224128     0       0   \n",
       "1 -1.499705          -1.499467            -1.500672 -0.958553     0       6   \n",
       "2 -1.499705          -1.499467            -1.500672 -0.958553     0       6   \n",
       "3 -1.499705          -1.499467            -1.500672 -0.958553     0       6   \n",
       "4 -1.499705          -1.499467            -1.500672 -0.958553     0       6   \n",
       "\n",
       "   Effect  Sequence Context  Original AA  New AA  AminoBefore  AminoAfter  \\\n",
       "0       0               186            6       3            3           3   \n",
       "1       0                90           12      20           10          18   \n",
       "2       0                90           12      20           10          18   \n",
       "3       0                90           12      20           10          18   \n",
       "4       0                90           12      20           10          18   \n",
       "\n",
       "   Locationingene  nitroBaseBef  nitroBaseAft  Severity  \n",
       "0              11             0             1         0  \n",
       "1               0             0             2         2  \n",
       "2               0             0             2         2  \n",
       "3               0             0             2         2  \n",
       "4               0             0             2         2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\"D:\\Github portfolio\\Hemophilia\\Hemophilia-Severity-Predictor\\datasets\\resampled_data_adasyn2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5332/5332 [==============================] - 13s 2ms/step - loss: 0.9669 - accuracy: 0.5051 - val_loss: 0.9065 - val_accuracy: 0.5529\n",
      "Epoch 2/10\n",
      "5332/5332 [==============================] - 13s 2ms/step - loss: 0.9118 - accuracy: 0.5521 - val_loss: 0.8909 - val_accuracy: 0.5596\n",
      "Epoch 3/10\n",
      "5332/5332 [==============================] - 13s 2ms/step - loss: 0.8884 - accuracy: 0.5696 - val_loss: 0.8695 - val_accuracy: 0.5769\n",
      "Epoch 4/10\n",
      "5332/5332 [==============================] - 13s 2ms/step - loss: 0.8706 - accuracy: 0.5848 - val_loss: 0.8955 - val_accuracy: 0.5626\n",
      "Epoch 5/10\n",
      "5332/5332 [==============================] - 13s 2ms/step - loss: 0.8569 - accuracy: 0.5955 - val_loss: 0.8738 - val_accuracy: 0.5986\n",
      "Epoch 6/10\n",
      "5332/5332 [==============================] - 14s 3ms/step - loss: 0.8395 - accuracy: 0.6092 - val_loss: 0.8594 - val_accuracy: 0.5994\n",
      "Epoch 7/10\n",
      "5332/5332 [==============================] - 13s 3ms/step - loss: 0.8301 - accuracy: 0.6131 - val_loss: 0.8447 - val_accuracy: 0.6099\n",
      "Epoch 8/10\n",
      "5332/5332 [==============================] - 14s 3ms/step - loss: 0.8214 - accuracy: 0.6197 - val_loss: 0.8499 - val_accuracy: 0.6152\n",
      "Epoch 9/10\n",
      "5332/5332 [==============================] - 14s 3ms/step - loss: 0.8090 - accuracy: 0.6332 - val_loss: 0.8537 - val_accuracy: 0.6159\n",
      "Epoch 10/10\n",
      "5332/5332 [==============================] - 14s 3ms/step - loss: 0.8008 - accuracy: 0.6337 - val_loss: 0.8446 - val_accuracy: 0.6122\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8584 - accuracy: 0.5909\n",
      "Loss: 0.8583940267562866\n",
      "Accuracy: 0.5908818244934082\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\"D:\\Github portfolio\\Hemophilia\\Hemophilia-Severity-Predictor\\datasets\\resampled_data_adasyn2.csv\")\n",
    "\n",
    "# Prepare data\n",
    "X = df[['cDNA', 'Amino acid (HGVS)', 'Amino acid (Legacy)', 'pos', 'Type', 'Domain', 'Effect', 'Sequence Context', 'Original AA', 'New AA', 'AminoBefore', 'AminoAfter', 'Locationingene', 'nitroBaseBef', 'nitroBaseAft']]\n",
    "y = df['Severity']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for RNN: (samples, timesteps, features)\n",
    "# Here, timesteps will be 1 because we're treating each sample as a single timestep\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes for Severity\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=1, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.5510060787200928\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\"D:\\Github portfolio\\Hemophilia\\Hemophilia-Severity-Predictor\\datasets\\resampled_data_adasyn2.csv\")\n",
    "\n",
    "# Prepare data\n",
    "X = df[['cDNA', 'Amino acid (HGVS)', 'Amino acid (Legacy)', 'pos', 'Type', 'Domain', 'Effect', 'Sequence Context', 'Original AA', 'New AA', 'AminoBefore', 'AminoAfter', 'Locationingene', 'nitroBaseBef', 'nitroBaseAft']]\n",
    "y = df['Severity']\n",
    "\n",
    "# Standardize features (optional, but recommended for RNNs)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for RNN: (samples, timesteps, features)\n",
    "# Here, timesteps will be 1 because we're treating each sample as a single timestep\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_reshaped):\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))  # 3 classes for Severity\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=1, verbose=0, validation_split=0.2)\n",
    "    \n",
    "    # Evaluate model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f'Average Accuracy: {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 2s 5ms/step - loss: 1.0545 - accuracy: 0.4509 - val_loss: 1.0279 - val_accuracy: 0.4721 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.0126 - accuracy: 0.4863 - val_loss: 1.0087 - val_accuracy: 0.4667 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9998 - accuracy: 0.4924 - val_loss: 0.9967 - val_accuracy: 0.4817 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9884 - accuracy: 0.5089 - val_loss: 0.9891 - val_accuracy: 0.5021 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9785 - accuracy: 0.5200 - val_loss: 0.9847 - val_accuracy: 0.5147 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9692 - accuracy: 0.5194 - val_loss: 0.9765 - val_accuracy: 0.5129 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9594 - accuracy: 0.5349 - val_loss: 0.9661 - val_accuracy: 0.5105 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9511 - accuracy: 0.5340 - val_loss: 0.9577 - val_accuracy: 0.5105 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9449 - accuracy: 0.5353 - val_loss: 0.9512 - val_accuracy: 0.5189 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9371 - accuracy: 0.5446 - val_loss: 0.9455 - val_accuracy: 0.5153 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9317 - accuracy: 0.5481 - val_loss: 0.9431 - val_accuracy: 0.5291 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9256 - accuracy: 0.5511 - val_loss: 0.9381 - val_accuracy: 0.5291 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9219 - accuracy: 0.5527 - val_loss: 0.9324 - val_accuracy: 0.5303 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9160 - accuracy: 0.5563 - val_loss: 0.9310 - val_accuracy: 0.5327 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9108 - accuracy: 0.5538 - val_loss: 0.9245 - val_accuracy: 0.5429 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9067 - accuracy: 0.5586 - val_loss: 0.9245 - val_accuracy: 0.5345 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9034 - accuracy: 0.5565 - val_loss: 0.9232 - val_accuracy: 0.5195 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9006 - accuracy: 0.5601 - val_loss: 0.9202 - val_accuracy: 0.5363 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.8978 - accuracy: 0.5640 - val_loss: 0.9149 - val_accuracy: 0.5399 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.8956 - accuracy: 0.5598 - val_loss: 0.9173 - val_accuracy: 0.5477 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.9173 - accuracy: 0.5477\n",
      "Fold 1 - Loss: 0.9172887802124023, Accuracy: 0.5476904511451721\n",
      "Processing fold 2\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 2s 5ms/step - loss: 1.0689 - accuracy: 0.4180 - val_loss: 1.0156 - val_accuracy: 0.4721 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.0113 - accuracy: 0.4686 - val_loss: 0.9937 - val_accuracy: 0.5039 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9964 - accuracy: 0.4861 - val_loss: 0.9869 - val_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9864 - accuracy: 0.4987 - val_loss: 0.9750 - val_accuracy: 0.5285 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9778 - accuracy: 0.5125 - val_loss: 0.9647 - val_accuracy: 0.5249 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9692 - accuracy: 0.5107 - val_loss: 0.9599 - val_accuracy: 0.5243 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.5169 - val_loss: 0.9494 - val_accuracy: 0.5357 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9577 - accuracy: 0.5205 - val_loss: 0.9422 - val_accuracy: 0.5333 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9508 - accuracy: 0.5235 - val_loss: 0.9390 - val_accuracy: 0.5429 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9460 - accuracy: 0.5224 - val_loss: 0.9342 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9416 - accuracy: 0.5295 - val_loss: 0.9283 - val_accuracy: 0.5513 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9356 - accuracy: 0.5349 - val_loss: 0.9245 - val_accuracy: 0.5495 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.9337 - accuracy: 0.5317 - val_loss: 0.9212 - val_accuracy: 0.5609 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9282 - accuracy: 0.5406 - val_loss: 0.9153 - val_accuracy: 0.5537 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9261 - accuracy: 0.5371 - val_loss: 0.9098 - val_accuracy: 0.5645 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9220 - accuracy: 0.5346 - val_loss: 0.9078 - val_accuracy: 0.5549 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9169 - accuracy: 0.5433 - val_loss: 0.9047 - val_accuracy: 0.5633 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9144 - accuracy: 0.5425 - val_loss: 0.9000 - val_accuracy: 0.5651 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9104 - accuracy: 0.5503 - val_loss: 0.8960 - val_accuracy: 0.5681 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9099 - accuracy: 0.5466 - val_loss: 0.8960 - val_accuracy: 0.5609 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8960 - accuracy: 0.5609\n",
      "Fold 2 - Loss: 0.8959963321685791, Accuracy: 0.5608878135681152\n",
      "Processing fold 3\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 2s 6ms/step - loss: 1.0492 - accuracy: 0.4523 - val_loss: 1.0153 - val_accuracy: 0.4730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0022 - accuracy: 0.4784 - val_loss: 1.0072 - val_accuracy: 0.4760 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.9882 - accuracy: 0.4931 - val_loss: 0.9913 - val_accuracy: 0.4772 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.9785 - accuracy: 0.5014 - val_loss: 0.9837 - val_accuracy: 0.4982 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.9690 - accuracy: 0.5147 - val_loss: 0.9770 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.9596 - accuracy: 0.5162 - val_loss: 0.9679 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.9529 - accuracy: 0.5305 - val_loss: 0.9584 - val_accuracy: 0.5204 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.9451 - accuracy: 0.5252 - val_loss: 0.9566 - val_accuracy: 0.5228 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.9399 - accuracy: 0.5282 - val_loss: 0.9503 - val_accuracy: 0.5384 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.9349 - accuracy: 0.5320 - val_loss: 0.9456 - val_accuracy: 0.5330 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9303 - accuracy: 0.5407 - val_loss: 0.9407 - val_accuracy: 0.5312 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.9255 - accuracy: 0.5374 - val_loss: 0.9366 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9207 - accuracy: 0.5431 - val_loss: 0.9333 - val_accuracy: 0.5456 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9150 - accuracy: 0.5419 - val_loss: 0.9354 - val_accuracy: 0.5264 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9122 - accuracy: 0.5527 - val_loss: 0.9309 - val_accuracy: 0.5354 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9100 - accuracy: 0.5491 - val_loss: 0.9229 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9055 - accuracy: 0.5540 - val_loss: 0.9227 - val_accuracy: 0.5438 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9021 - accuracy: 0.5561 - val_loss: 0.9209 - val_accuracy: 0.5402 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9003 - accuracy: 0.5518 - val_loss: 0.9250 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.8963 - accuracy: 0.5611 - val_loss: 0.9189 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.9189 - accuracy: 0.5420\n",
      "Fold 3 - Loss: 0.9189367294311523, Accuracy: 0.5420168042182922\n",
      "Processing fold 4\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 2s 6ms/step - loss: 1.0525 - accuracy: 0.4433 - val_loss: 1.0251 - val_accuracy: 0.4496 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.0039 - accuracy: 0.4824 - val_loss: 1.0156 - val_accuracy: 0.4688 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9934 - accuracy: 0.4872 - val_loss: 1.0053 - val_accuracy: 0.4790 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9838 - accuracy: 0.4989 - val_loss: 0.9981 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.5132 - val_loss: 0.9887 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9655 - accuracy: 0.5197 - val_loss: 0.9814 - val_accuracy: 0.5066 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9570 - accuracy: 0.5278 - val_loss: 0.9769 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9497 - accuracy: 0.5243 - val_loss: 0.9683 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9424 - accuracy: 0.5240 - val_loss: 0.9626 - val_accuracy: 0.4976 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9364 - accuracy: 0.5318 - val_loss: 0.9589 - val_accuracy: 0.5012 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9301 - accuracy: 0.5333 - val_loss: 0.9558 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9251 - accuracy: 0.5408 - val_loss: 0.9495 - val_accuracy: 0.4982 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9204 - accuracy: 0.5368 - val_loss: 0.9477 - val_accuracy: 0.5042 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9171 - accuracy: 0.5342 - val_loss: 0.9412 - val_accuracy: 0.5198 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9121 - accuracy: 0.5465 - val_loss: 0.9381 - val_accuracy: 0.5120 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9076 - accuracy: 0.5443 - val_loss: 0.9348 - val_accuracy: 0.5180 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9043 - accuracy: 0.5531 - val_loss: 0.9315 - val_accuracy: 0.5216 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.8996 - accuracy: 0.5507 - val_loss: 0.9329 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.8965 - accuracy: 0.5501 - val_loss: 0.9237 - val_accuracy: 0.5264 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.8939 - accuracy: 0.5525 - val_loss: 0.9260 - val_accuracy: 0.5228 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.9260 - accuracy: 0.5228\n",
      "Fold 4 - Loss: 0.9259966015815735, Accuracy: 0.5228091478347778\n",
      "Processing fold 5\n",
      "Epoch 1/20\n",
      "105/105 [==============================] - 2s 5ms/step - loss: 1.0607 - accuracy: 0.4467 - val_loss: 1.0078 - val_accuracy: 0.5012 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.0082 - accuracy: 0.4782 - val_loss: 0.9947 - val_accuracy: 0.5168 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9975 - accuracy: 0.4844 - val_loss: 0.9844 - val_accuracy: 0.5096 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9892 - accuracy: 0.4968 - val_loss: 0.9764 - val_accuracy: 0.5258 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9796 - accuracy: 0.5113 - val_loss: 0.9681 - val_accuracy: 0.5234 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.5083 - val_loss: 0.9656 - val_accuracy: 0.5186 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9641 - accuracy: 0.5107 - val_loss: 0.9587 - val_accuracy: 0.5234 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9567 - accuracy: 0.5192 - val_loss: 0.9468 - val_accuracy: 0.5210 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9511 - accuracy: 0.5218 - val_loss: 0.9409 - val_accuracy: 0.5342 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9434 - accuracy: 0.5291 - val_loss: 0.9350 - val_accuracy: 0.5504 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9376 - accuracy: 0.5354 - val_loss: 0.9310 - val_accuracy: 0.5276 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9327 - accuracy: 0.5314 - val_loss: 0.9293 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9274 - accuracy: 0.5449 - val_loss: 0.9266 - val_accuracy: 0.5294 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9224 - accuracy: 0.5431 - val_loss: 0.9226 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9182 - accuracy: 0.5456 - val_loss: 0.9112 - val_accuracy: 0.5504 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9133 - accuracy: 0.5441 - val_loss: 0.9084 - val_accuracy: 0.5528 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9103 - accuracy: 0.5501 - val_loss: 0.9061 - val_accuracy: 0.5534 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.9059 - accuracy: 0.5477 - val_loss: 0.9098 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9019 - accuracy: 0.5566 - val_loss: 0.9014 - val_accuracy: 0.5474 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.9002 - accuracy: 0.5551 - val_loss: 0.8972 - val_accuracy: 0.5648 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8972 - accuracy: 0.5648\n",
      "Fold 5 - Loss: 0.897226095199585, Accuracy: 0.5648259520530701\n",
      "Average Accuracy across all folds: 0.5476460337638855\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(r\"D:\\Github portfolio\\Hemophilia\\Hemophilia-Severity-Predictor\\datasets\\resampled_data_adasyn2.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=['Severity'])\n",
    "y = df['Severity']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    print(f\"Processing fold {fold}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_val = y_one_hot[train_index], y_one_hot[val_index]\n",
    "    \n",
    "    # Reshape for RNN\n",
    "    X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_val_rnn = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "    \n",
    "    # Define the RNN model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=50, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=False))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_rnn, y_train, epochs=20, batch_size=64, validation_data=(X_val_rnn, y_val),\n",
    "                        callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_val_rnn, y_val)\n",
    "    print(f'Fold {fold} - Loss: {loss}, Accuracy: {accuracy}')\n",
    "    \n",
    "    # Store the accuracy of this fold\n",
    "    fold_accuracies.append(accuracy)\n",
    "    \n",
    "    # Increment fold counter\n",
    "    fold += 1\n",
    "\n",
    "    # Clear the model from memory\n",
    "    K.clear_session()\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f'Average Accuracy across all folds: {average_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Epoch 1/30\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 1.0284 - accuracy: 0.4614 - val_loss: 0.9695 - val_accuracy: 0.5003 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9582 - accuracy: 0.5175 - val_loss: 0.9581 - val_accuracy: 0.5195 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9454 - accuracy: 0.5296 - val_loss: 0.9402 - val_accuracy: 0.5117 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9301 - accuracy: 0.5386 - val_loss: 0.9399 - val_accuracy: 0.5237 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9239 - accuracy: 0.5427 - val_loss: 0.9387 - val_accuracy: 0.5189 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9177 - accuracy: 0.5443 - val_loss: 0.9257 - val_accuracy: 0.5171 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9139 - accuracy: 0.5508 - val_loss: 0.9201 - val_accuracy: 0.5339 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9067 - accuracy: 0.5526 - val_loss: 0.9197 - val_accuracy: 0.5321 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9002 - accuracy: 0.5589 - val_loss: 0.9119 - val_accuracy: 0.5423 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8985 - accuracy: 0.5632 - val_loss: 0.9066 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8955 - accuracy: 0.5605 - val_loss: 0.9079 - val_accuracy: 0.5453 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.8932 - accuracy: 0.5673 - val_loss: 0.9063 - val_accuracy: 0.5267 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8843 - accuracy: 0.5746 - val_loss: 0.9044 - val_accuracy: 0.5453 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8838 - accuracy: 0.5721 - val_loss: 0.8973 - val_accuracy: 0.5489 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8842 - accuracy: 0.5751 - val_loss: 0.8959 - val_accuracy: 0.5429 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8825 - accuracy: 0.5698 - val_loss: 0.8869 - val_accuracy: 0.5573 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8849 - accuracy: 0.5760 - val_loss: 0.8893 - val_accuracy: 0.5645 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8780 - accuracy: 0.5845 - val_loss: 0.8878 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8721 - accuracy: 0.5863 - val_loss: 0.8877 - val_accuracy: 0.5663 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8760 - accuracy: 0.5826 - val_loss: 0.8831 - val_accuracy: 0.5651 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8672 - accuracy: 0.5896 - val_loss: 0.8878 - val_accuracy: 0.5663 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8729 - accuracy: 0.5836 - val_loss: 0.8821 - val_accuracy: 0.5705 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8688 - accuracy: 0.5898 - val_loss: 0.8758 - val_accuracy: 0.5651 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8667 - accuracy: 0.5899 - val_loss: 0.8764 - val_accuracy: 0.5771 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8672 - accuracy: 0.5910 - val_loss: 0.8774 - val_accuracy: 0.5819 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8644 - accuracy: 0.5938 - val_loss: 0.8697 - val_accuracy: 0.5855 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8618 - accuracy: 0.5887 - val_loss: 0.8732 - val_accuracy: 0.5753 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8630 - accuracy: 0.5881 - val_loss: 0.8697 - val_accuracy: 0.5747 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8574 - accuracy: 0.5988 - val_loss: 0.8689 - val_accuracy: 0.5741 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8601 - accuracy: 0.5970 - val_loss: 0.8684 - val_accuracy: 0.5837 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.5837\n",
      "Fold 1 - Loss: 0.8683841228485107, Accuracy: 0.5836832523345947\n",
      "Processing fold 2\n",
      "Epoch 1/30\n",
      "209/209 [==============================] - 3s 6ms/step - loss: 1.0216 - accuracy: 0.4590 - val_loss: 0.9421 - val_accuracy: 0.5435 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9690 - accuracy: 0.5110 - val_loss: 0.9201 - val_accuracy: 0.5333 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9527 - accuracy: 0.5175 - val_loss: 0.9057 - val_accuracy: 0.5681 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9396 - accuracy: 0.5275 - val_loss: 0.8928 - val_accuracy: 0.5561 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9322 - accuracy: 0.5338 - val_loss: 0.8896 - val_accuracy: 0.5669 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.9250 - accuracy: 0.5422 - val_loss: 0.8835 - val_accuracy: 0.5699 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9207 - accuracy: 0.5454 - val_loss: 0.8785 - val_accuracy: 0.5747 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9199 - accuracy: 0.5433 - val_loss: 0.8746 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9134 - accuracy: 0.5482 - val_loss: 0.8736 - val_accuracy: 0.5735 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9090 - accuracy: 0.5541 - val_loss: 0.8727 - val_accuracy: 0.5771 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9074 - accuracy: 0.5556 - val_loss: 0.8664 - val_accuracy: 0.5801 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9030 - accuracy: 0.5562 - val_loss: 0.8593 - val_accuracy: 0.5849 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9042 - accuracy: 0.5523 - val_loss: 0.8599 - val_accuracy: 0.5795 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8972 - accuracy: 0.5652 - val_loss: 0.8583 - val_accuracy: 0.5867 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8947 - accuracy: 0.5656 - val_loss: 0.8557 - val_accuracy: 0.6059 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8941 - accuracy: 0.5670 - val_loss: 0.8593 - val_accuracy: 0.5807 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8871 - accuracy: 0.5748 - val_loss: 0.8540 - val_accuracy: 0.6005 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8853 - accuracy: 0.5740 - val_loss: 0.8507 - val_accuracy: 0.5903 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8907 - accuracy: 0.5643 - val_loss: 0.8517 - val_accuracy: 0.5957 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8822 - accuracy: 0.5758 - val_loss: 0.8529 - val_accuracy: 0.5987 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.8778 - accuracy: 0.5800 - val_loss: 0.8540 - val_accuracy: 0.5879 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8788 - accuracy: 0.5761 - val_loss: 0.8412 - val_accuracy: 0.5915 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8783 - accuracy: 0.5824 - val_loss: 0.8461 - val_accuracy: 0.6101 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8776 - accuracy: 0.5751 - val_loss: 0.8429 - val_accuracy: 0.6071 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8757 - accuracy: 0.5847 - val_loss: 0.8367 - val_accuracy: 0.6083 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8730 - accuracy: 0.5821 - val_loss: 0.8336 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8732 - accuracy: 0.5796 - val_loss: 0.8363 - val_accuracy: 0.6083 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8668 - accuracy: 0.5880 - val_loss: 0.8408 - val_accuracy: 0.6107 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8679 - accuracy: 0.5845 - val_loss: 0.8348 - val_accuracy: 0.6107 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8699 - accuracy: 0.5875 - val_loss: 0.8308 - val_accuracy: 0.6155 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.8308 - accuracy: 0.6155\n",
      "Fold 2 - Loss: 0.830779492855072, Accuracy: 0.6154769062995911\n",
      "Processing fold 3\n",
      "Epoch 1/30\n",
      "209/209 [==============================] - 3s 5ms/step - loss: 1.0190 - accuracy: 0.4704 - val_loss: 0.9709 - val_accuracy: 0.4994 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9638 - accuracy: 0.5014 - val_loss: 0.9537 - val_accuracy: 0.5096 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9421 - accuracy: 0.5170 - val_loss: 0.9345 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9265 - accuracy: 0.5321 - val_loss: 0.9296 - val_accuracy: 0.5342 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9220 - accuracy: 0.5417 - val_loss: 0.9261 - val_accuracy: 0.5402 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9203 - accuracy: 0.5431 - val_loss: 0.9245 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9092 - accuracy: 0.5500 - val_loss: 0.9162 - val_accuracy: 0.5312 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9061 - accuracy: 0.5528 - val_loss: 0.9118 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9021 - accuracy: 0.5549 - val_loss: 0.9121 - val_accuracy: 0.5618 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8995 - accuracy: 0.5597 - val_loss: 0.9057 - val_accuracy: 0.5540 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8958 - accuracy: 0.5576 - val_loss: 0.9070 - val_accuracy: 0.5522 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8948 - accuracy: 0.5602 - val_loss: 0.9027 - val_accuracy: 0.5582 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8881 - accuracy: 0.5600 - val_loss: 0.8989 - val_accuracy: 0.5612 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8923 - accuracy: 0.5681 - val_loss: 0.8935 - val_accuracy: 0.5696 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8828 - accuracy: 0.5755 - val_loss: 0.9017 - val_accuracy: 0.5594 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8797 - accuracy: 0.5687 - val_loss: 0.8880 - val_accuracy: 0.5654 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8777 - accuracy: 0.5783 - val_loss: 0.8898 - val_accuracy: 0.5582 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8774 - accuracy: 0.5759 - val_loss: 0.8899 - val_accuracy: 0.5534 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8733 - accuracy: 0.5780 - val_loss: 0.8851 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8726 - accuracy: 0.5737 - val_loss: 0.8846 - val_accuracy: 0.5780 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8679 - accuracy: 0.5818 - val_loss: 0.8795 - val_accuracy: 0.5684 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8717 - accuracy: 0.5767 - val_loss: 0.8812 - val_accuracy: 0.5798 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8670 - accuracy: 0.5825 - val_loss: 0.8919 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8669 - accuracy: 0.5854 - val_loss: 0.8751 - val_accuracy: 0.5882 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8601 - accuracy: 0.5885 - val_loss: 0.8769 - val_accuracy: 0.5822 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.8617 - accuracy: 0.5828 - val_loss: 0.8673 - val_accuracy: 0.5876 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8611 - accuracy: 0.5957 - val_loss: 0.8729 - val_accuracy: 0.5978 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8520 - accuracy: 0.5972 - val_loss: 0.8643 - val_accuracy: 0.5936 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8531 - accuracy: 0.5972 - val_loss: 0.8789 - val_accuracy: 0.5876 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8522 - accuracy: 0.5933 - val_loss: 0.8647 - val_accuracy: 0.5948 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8647 - accuracy: 0.5948\n",
      "Fold 3 - Loss: 0.8646937608718872, Accuracy: 0.5948379635810852\n",
      "Processing fold 4\n",
      "Epoch 1/30\n",
      "209/209 [==============================] - 3s 7ms/step - loss: 1.0231 - accuracy: 0.4694 - val_loss: 0.9694 - val_accuracy: 0.5042 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9706 - accuracy: 0.5120 - val_loss: 0.9476 - val_accuracy: 0.5126 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9461 - accuracy: 0.5254 - val_loss: 0.9467 - val_accuracy: 0.5162 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9348 - accuracy: 0.5320 - val_loss: 0.9318 - val_accuracy: 0.5294 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9233 - accuracy: 0.5470 - val_loss: 0.9358 - val_accuracy: 0.5402 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9215 - accuracy: 0.5465 - val_loss: 0.9290 - val_accuracy: 0.5366 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9133 - accuracy: 0.5539 - val_loss: 0.9149 - val_accuracy: 0.5564 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9081 - accuracy: 0.5543 - val_loss: 0.9258 - val_accuracy: 0.5492 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9077 - accuracy: 0.5452 - val_loss: 0.9101 - val_accuracy: 0.5570 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9047 - accuracy: 0.5521 - val_loss: 0.9072 - val_accuracy: 0.5504 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8991 - accuracy: 0.5581 - val_loss: 0.9069 - val_accuracy: 0.5726 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8931 - accuracy: 0.5602 - val_loss: 0.9009 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8935 - accuracy: 0.5635 - val_loss: 0.9052 - val_accuracy: 0.5648 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8865 - accuracy: 0.5737 - val_loss: 0.9013 - val_accuracy: 0.5696 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8867 - accuracy: 0.5668 - val_loss: 0.9035 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8788 - accuracy: 0.5707 - val_loss: 0.8922 - val_accuracy: 0.5588 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8834 - accuracy: 0.5735 - val_loss: 0.8951 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8754 - accuracy: 0.5807 - val_loss: 0.8949 - val_accuracy: 0.5690 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.8756 - accuracy: 0.5785 - val_loss: 0.8944 - val_accuracy: 0.5744 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8767 - accuracy: 0.5791 - val_loss: 0.8940 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.8610 - accuracy: 0.5888 - val_loss: 0.8887 - val_accuracy: 0.5684 - lr: 5.0000e-04\n",
      "Epoch 22/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8632 - accuracy: 0.5848 - val_loss: 0.8832 - val_accuracy: 0.5798 - lr: 5.0000e-04\n",
      "Epoch 23/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8641 - accuracy: 0.5851 - val_loss: 0.8872 - val_accuracy: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 24/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8603 - accuracy: 0.5942 - val_loss: 0.8860 - val_accuracy: 0.5750 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8590 - accuracy: 0.5869 - val_loss: 0.8779 - val_accuracy: 0.5804 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8593 - accuracy: 0.5921 - val_loss: 0.8777 - val_accuracy: 0.5906 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8539 - accuracy: 0.5927 - val_loss: 0.8797 - val_accuracy: 0.5822 - lr: 5.0000e-04\n",
      "Epoch 28/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8583 - accuracy: 0.5908 - val_loss: 0.8792 - val_accuracy: 0.5864 - lr: 5.0000e-04\n",
      "Epoch 29/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8569 - accuracy: 0.5921 - val_loss: 0.8782 - val_accuracy: 0.5906 - lr: 5.0000e-04\n",
      "Epoch 30/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.8519 - accuracy: 0.6038 - val_loss: 0.8797 - val_accuracy: 0.5972 - lr: 5.0000e-04\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8797 - accuracy: 0.5972\n",
      "Fold 4 - Loss: 0.8797029256820679, Accuracy: 0.5972388982772827\n",
      "Processing fold 5\n",
      "Epoch 1/30\n",
      "209/209 [==============================] - 3s 4ms/step - loss: 1.0242 - accuracy: 0.4520 - val_loss: 0.9415 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.9665 - accuracy: 0.4991 - val_loss: 0.9290 - val_accuracy: 0.5210 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.9446 - accuracy: 0.5282 - val_loss: 0.9135 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.9349 - accuracy: 0.5297 - val_loss: 0.9078 - val_accuracy: 0.5606 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - 1s 4ms/step - loss: 0.9262 - accuracy: 0.5323 - val_loss: 0.8993 - val_accuracy: 0.5684 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.9168 - accuracy: 0.5408 - val_loss: 0.8983 - val_accuracy: 0.5558 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - 2s 7ms/step - loss: 0.9166 - accuracy: 0.5425 - val_loss: 0.8933 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - 4s 18ms/step - loss: 0.9145 - accuracy: 0.5461 - val_loss: 0.8957 - val_accuracy: 0.5570 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - 5s 23ms/step - loss: 0.9112 - accuracy: 0.5465 - val_loss: 0.8873 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - 3s 13ms/step - loss: 0.9058 - accuracy: 0.5492 - val_loss: 0.8823 - val_accuracy: 0.5816 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 0.9015 - accuracy: 0.5566 - val_loss: 0.8885 - val_accuracy: 0.5630 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 0.9022 - accuracy: 0.5569 - val_loss: 0.8777 - val_accuracy: 0.5738 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 0.8977 - accuracy: 0.5606 - val_loss: 0.8795 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8938 - accuracy: 0.5665 - val_loss: 0.8737 - val_accuracy: 0.5792 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - 1s 7ms/step - loss: 0.8929 - accuracy: 0.5714 - val_loss: 0.8745 - val_accuracy: 0.5726 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8894 - accuracy: 0.5690 - val_loss: 0.8766 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8866 - accuracy: 0.5753 - val_loss: 0.8730 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8845 - accuracy: 0.5725 - val_loss: 0.8712 - val_accuracy: 0.5780 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - 1s 7ms/step - loss: 0.8833 - accuracy: 0.5749 - val_loss: 0.8667 - val_accuracy: 0.5810 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8826 - accuracy: 0.5726 - val_loss: 0.8735 - val_accuracy: 0.5780 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8782 - accuracy: 0.5713 - val_loss: 0.8702 - val_accuracy: 0.5792 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8770 - accuracy: 0.5791 - val_loss: 0.8641 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8727 - accuracy: 0.5852 - val_loss: 0.8607 - val_accuracy: 0.5846 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8724 - accuracy: 0.5780 - val_loss: 0.8653 - val_accuracy: 0.5864 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8698 - accuracy: 0.5794 - val_loss: 0.8583 - val_accuracy: 0.5834 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8699 - accuracy: 0.5795 - val_loss: 0.8545 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "209/209 [==============================] - 1s 7ms/step - loss: 0.8672 - accuracy: 0.5881 - val_loss: 0.8565 - val_accuracy: 0.5798 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8642 - accuracy: 0.5863 - val_loss: 0.8606 - val_accuracy: 0.5780 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "209/209 [==============================] - 1s 7ms/step - loss: 0.8643 - accuracy: 0.5852 - val_loss: 0.8525 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 0.8595 - accuracy: 0.5848 - val_loss: 0.8538 - val_accuracy: 0.5816 - lr: 0.0010\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.8538 - accuracy: 0.5816\n",
      "Fold 5 - Loss: 0.853765606880188, Accuracy: 0.581632673740387\n",
      "Average Accuracy across all folds: 0.5945739388465882\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(r\"D:\\Github portfolio\\Hemophilia\\Hemophilia-Severity-Predictor\\datasets\\resampled_data_adasyn2.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=['Severity'])\n",
    "y = df['Severity']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    print(f\"Processing fold {fold}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_val = y_one_hot[train_index], y_one_hot[val_index]\n",
    "    \n",
    "    # Reshape for RNN\n",
    "    X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_val_rnn = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "    \n",
    "    # Define the RNN model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=100, activation='tanh', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model with a lower learning rate\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_rnn, y_train, epochs=30, batch_size=32, validation_data=(X_val_rnn, y_val),\n",
    "                        callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_val_rnn, y_val)\n",
    "    print(f'Fold {fold} - Loss: {loss}, Accuracy: {accuracy}')\n",
    "    \n",
    "    # Store the accuracy of this fold\n",
    "    fold_accuracies.append(accuracy)\n",
    "    \n",
    "    # Increment fold counter\n",
    "    fold += 1\n",
    "\n",
    "    # Clear the model from memory\n",
    "    K.clear_session()\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f'Average Accuracy across all folds: {average_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Stratified K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Epoch 1/50\n",
      "417/417 [==============================] - 4s 5ms/step - loss: 1.0226 - accuracy: 0.4606 - val_loss: 0.9464 - val_accuracy: 0.5345 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9707 - accuracy: 0.4989 - val_loss: 0.9276 - val_accuracy: 0.5297 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "417/417 [==============================] - 1s 4ms/step - loss: 0.9531 - accuracy: 0.5146 - val_loss: 0.9172 - val_accuracy: 0.5393 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "417/417 [==============================] - 1s 3ms/step - loss: 0.9464 - accuracy: 0.5226 - val_loss: 0.9131 - val_accuracy: 0.5489 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "417/417 [==============================] - 1s 4ms/step - loss: 0.9381 - accuracy: 0.5229 - val_loss: 0.9054 - val_accuracy: 0.5375 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9284 - accuracy: 0.5347 - val_loss: 0.9047 - val_accuracy: 0.5537 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "417/417 [==============================] - 1s 3ms/step - loss: 0.9236 - accuracy: 0.5412 - val_loss: 0.8982 - val_accuracy: 0.5567 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9184 - accuracy: 0.5407 - val_loss: 0.8923 - val_accuracy: 0.5735 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9189 - accuracy: 0.5391 - val_loss: 0.8916 - val_accuracy: 0.5705 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9134 - accuracy: 0.5472 - val_loss: 0.8896 - val_accuracy: 0.5639 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9097 - accuracy: 0.5461 - val_loss: 0.8891 - val_accuracy: 0.5669 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9086 - accuracy: 0.5413 - val_loss: 0.8802 - val_accuracy: 0.5693 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9025 - accuracy: 0.5602 - val_loss: 0.8840 - val_accuracy: 0.5777 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.9030 - accuracy: 0.5530 - val_loss: 0.8822 - val_accuracy: 0.5777 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9019 - accuracy: 0.5583 - val_loss: 0.8752 - val_accuracy: 0.5939 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8982 - accuracy: 0.5595 - val_loss: 0.8844 - val_accuracy: 0.5807 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8905 - accuracy: 0.5649 - val_loss: 0.8714 - val_accuracy: 0.5795 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8864 - accuracy: 0.5637 - val_loss: 0.8698 - val_accuracy: 0.5807 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8853 - accuracy: 0.5716 - val_loss: 0.8689 - val_accuracy: 0.5951 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8818 - accuracy: 0.5748 - val_loss: 0.8616 - val_accuracy: 0.5855 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8850 - accuracy: 0.5719 - val_loss: 0.8650 - val_accuracy: 0.5927 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8792 - accuracy: 0.5746 - val_loss: 0.8743 - val_accuracy: 0.5891 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8806 - accuracy: 0.5724 - val_loss: 0.8589 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8722 - accuracy: 0.5802 - val_loss: 0.8543 - val_accuracy: 0.5975 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8754 - accuracy: 0.5782 - val_loss: 0.8525 - val_accuracy: 0.5981 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8742 - accuracy: 0.5788 - val_loss: 0.8523 - val_accuracy: 0.5897 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8703 - accuracy: 0.5788 - val_loss: 0.8572 - val_accuracy: 0.5855 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8688 - accuracy: 0.5808 - val_loss: 0.8492 - val_accuracy: 0.6011 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8659 - accuracy: 0.5866 - val_loss: 0.8474 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8631 - accuracy: 0.5898 - val_loss: 0.8466 - val_accuracy: 0.6017 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8619 - accuracy: 0.5829 - val_loss: 0.8416 - val_accuracy: 0.6137 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8625 - accuracy: 0.5896 - val_loss: 0.8435 - val_accuracy: 0.5963 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8669 - accuracy: 0.5910 - val_loss: 0.8400 - val_accuracy: 0.6011 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8572 - accuracy: 0.5904 - val_loss: 0.8452 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8558 - accuracy: 0.5910 - val_loss: 0.8467 - val_accuracy: 0.5939 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8530 - accuracy: 0.5967 - val_loss: 0.8419 - val_accuracy: 0.5999 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.8417 - accuracy: 0.6015 - val_loss: 0.8353 - val_accuracy: 0.6107 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8465 - accuracy: 0.5977 - val_loss: 0.8315 - val_accuracy: 0.6149 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8427 - accuracy: 0.5995 - val_loss: 0.8294 - val_accuracy: 0.6149 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8392 - accuracy: 0.6056 - val_loss: 0.8374 - val_accuracy: 0.6095 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.8438 - accuracy: 0.5974 - val_loss: 0.8261 - val_accuracy: 0.6227 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8446 - accuracy: 0.5953 - val_loss: 0.8299 - val_accuracy: 0.6149 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8412 - accuracy: 0.6030 - val_loss: 0.8239 - val_accuracy: 0.6137 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8369 - accuracy: 0.6045 - val_loss: 0.8303 - val_accuracy: 0.6143 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8370 - accuracy: 0.6029 - val_loss: 0.8285 - val_accuracy: 0.6167 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8366 - accuracy: 0.6012 - val_loss: 0.8245 - val_accuracy: 0.6167 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8301 - accuracy: 0.6105 - val_loss: 0.8229 - val_accuracy: 0.6137 - lr: 2.5000e-04\n",
      "Epoch 48/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8289 - accuracy: 0.6120 - val_loss: 0.8217 - val_accuracy: 0.6191 - lr: 2.5000e-04\n",
      "Epoch 49/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8298 - accuracy: 0.6155 - val_loss: 0.8195 - val_accuracy: 0.6185 - lr: 2.5000e-04\n",
      "Epoch 50/50\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.8250 - accuracy: 0.6138 - val_loss: 0.8191 - val_accuracy: 0.6227 - lr: 2.5000e-04\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.8191 - accuracy: 0.6227\n",
      "Fold 1 - Loss: 0.8190934062004089, Accuracy: 0.6226754784584045\n",
      "Processing fold 2\n",
      "Epoch 1/50\n",
      "417/417 [==============================] - 5s 6ms/step - loss: 1.0242 - accuracy: 0.4539 - val_loss: 0.9479 - val_accuracy: 0.5219 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9700 - accuracy: 0.5091 - val_loss: 0.9358 - val_accuracy: 0.5411 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9582 - accuracy: 0.5191 - val_loss: 0.9197 - val_accuracy: 0.5477 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9428 - accuracy: 0.5287 - val_loss: 0.9104 - val_accuracy: 0.5501 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9334 - accuracy: 0.5253 - val_loss: 0.9055 - val_accuracy: 0.5411 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9318 - accuracy: 0.5308 - val_loss: 0.9009 - val_accuracy: 0.5651 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9250 - accuracy: 0.5320 - val_loss: 0.9040 - val_accuracy: 0.5627 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9260 - accuracy: 0.5368 - val_loss: 0.9034 - val_accuracy: 0.5573 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9147 - accuracy: 0.5472 - val_loss: 0.9070 - val_accuracy: 0.5489 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9055 - accuracy: 0.5545 - val_loss: 0.8924 - val_accuracy: 0.5645 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9031 - accuracy: 0.5515 - val_loss: 0.8857 - val_accuracy: 0.5699 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9002 - accuracy: 0.5590 - val_loss: 0.8902 - val_accuracy: 0.5543 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8963 - accuracy: 0.5658 - val_loss: 0.8830 - val_accuracy: 0.5693 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8932 - accuracy: 0.5608 - val_loss: 0.8766 - val_accuracy: 0.5771 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8955 - accuracy: 0.5571 - val_loss: 0.8779 - val_accuracy: 0.5657 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8911 - accuracy: 0.5623 - val_loss: 0.8750 - val_accuracy: 0.5633 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8878 - accuracy: 0.5622 - val_loss: 0.8735 - val_accuracy: 0.5705 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8855 - accuracy: 0.5709 - val_loss: 0.8786 - val_accuracy: 0.5813 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8872 - accuracy: 0.5716 - val_loss: 0.8747 - val_accuracy: 0.5699 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8791 - accuracy: 0.5725 - val_loss: 0.8726 - val_accuracy: 0.5657 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8829 - accuracy: 0.5728 - val_loss: 0.8664 - val_accuracy: 0.5789 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8833 - accuracy: 0.5706 - val_loss: 0.8713 - val_accuracy: 0.5681 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8799 - accuracy: 0.5727 - val_loss: 0.8618 - val_accuracy: 0.5831 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8781 - accuracy: 0.5745 - val_loss: 0.8657 - val_accuracy: 0.5831 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8749 - accuracy: 0.5778 - val_loss: 0.8647 - val_accuracy: 0.5879 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8695 - accuracy: 0.5757 - val_loss: 0.8629 - val_accuracy: 0.5897 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8733 - accuracy: 0.5797 - val_loss: 0.8583 - val_accuracy: 0.5873 - lr: 2.5000e-04\n",
      "Epoch 28/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8691 - accuracy: 0.5829 - val_loss: 0.8594 - val_accuracy: 0.5813 - lr: 2.5000e-04\n",
      "Epoch 29/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8707 - accuracy: 0.5800 - val_loss: 0.8545 - val_accuracy: 0.5885 - lr: 2.5000e-04\n",
      "Epoch 30/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8627 - accuracy: 0.5869 - val_loss: 0.8538 - val_accuracy: 0.5873 - lr: 2.5000e-04\n",
      "Epoch 31/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8612 - accuracy: 0.5884 - val_loss: 0.8526 - val_accuracy: 0.5879 - lr: 2.5000e-04\n",
      "Epoch 32/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8654 - accuracy: 0.5866 - val_loss: 0.8532 - val_accuracy: 0.5891 - lr: 2.5000e-04\n",
      "Epoch 33/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8614 - accuracy: 0.5872 - val_loss: 0.8556 - val_accuracy: 0.5873 - lr: 2.5000e-04\n",
      "Epoch 34/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8650 - accuracy: 0.5878 - val_loss: 0.8541 - val_accuracy: 0.5843 - lr: 2.5000e-04\n",
      "Epoch 35/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8582 - accuracy: 0.5913 - val_loss: 0.8515 - val_accuracy: 0.5843 - lr: 1.2500e-04\n",
      "Epoch 36/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8574 - accuracy: 0.5938 - val_loss: 0.8514 - val_accuracy: 0.5849 - lr: 1.2500e-04\n",
      "Epoch 37/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8534 - accuracy: 0.5989 - val_loss: 0.8488 - val_accuracy: 0.5873 - lr: 1.2500e-04\n",
      "Epoch 38/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8565 - accuracy: 0.5946 - val_loss: 0.8506 - val_accuracy: 0.5873 - lr: 1.2500e-04\n",
      "Epoch 39/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8571 - accuracy: 0.5916 - val_loss: 0.8494 - val_accuracy: 0.5897 - lr: 1.2500e-04\n",
      "Epoch 40/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8510 - accuracy: 0.5982 - val_loss: 0.8494 - val_accuracy: 0.5861 - lr: 1.2500e-04\n",
      "Epoch 41/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8578 - accuracy: 0.5919 - val_loss: 0.8494 - val_accuracy: 0.5903 - lr: 6.2500e-05\n",
      "Epoch 42/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8594 - accuracy: 0.5926 - val_loss: 0.8485 - val_accuracy: 0.5873 - lr: 6.2500e-05\n",
      "Epoch 43/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8525 - accuracy: 0.5940 - val_loss: 0.8481 - val_accuracy: 0.5891 - lr: 6.2500e-05\n",
      "Epoch 44/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8557 - accuracy: 0.5913 - val_loss: 0.8471 - val_accuracy: 0.5867 - lr: 6.2500e-05\n",
      "Epoch 45/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8531 - accuracy: 0.5937 - val_loss: 0.8474 - val_accuracy: 0.5879 - lr: 6.2500e-05\n",
      "Epoch 46/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8615 - accuracy: 0.5839 - val_loss: 0.8472 - val_accuracy: 0.5867 - lr: 6.2500e-05\n",
      "Epoch 47/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8549 - accuracy: 0.5887 - val_loss: 0.8474 - val_accuracy: 0.5873 - lr: 6.2500e-05\n",
      "Epoch 48/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8543 - accuracy: 0.5923 - val_loss: 0.8471 - val_accuracy: 0.5915 - lr: 3.1250e-05\n",
      "Epoch 49/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8567 - accuracy: 0.5932 - val_loss: 0.8468 - val_accuracy: 0.5903 - lr: 3.1250e-05\n",
      "Epoch 50/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8487 - accuracy: 0.5985 - val_loss: 0.8464 - val_accuracy: 0.5873 - lr: 3.1250e-05\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8464 - accuracy: 0.5873\n",
      "Fold 2 - Loss: 0.8464125990867615, Accuracy: 0.5872825384140015\n",
      "Processing fold 3\n",
      "Epoch 1/50\n",
      "417/417 [==============================] - 5s 6ms/step - loss: 1.0174 - accuracy: 0.4670 - val_loss: 0.9661 - val_accuracy: 0.5012 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9693 - accuracy: 0.5018 - val_loss: 0.9460 - val_accuracy: 0.5258 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9517 - accuracy: 0.5143 - val_loss: 0.9369 - val_accuracy: 0.5186 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9320 - accuracy: 0.5318 - val_loss: 0.9191 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9335 - accuracy: 0.5309 - val_loss: 0.9145 - val_accuracy: 0.5450 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9260 - accuracy: 0.5387 - val_loss: 0.9185 - val_accuracy: 0.5534 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9279 - accuracy: 0.5306 - val_loss: 0.9010 - val_accuracy: 0.5600 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9151 - accuracy: 0.5489 - val_loss: 0.8975 - val_accuracy: 0.5600 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9192 - accuracy: 0.5422 - val_loss: 0.9024 - val_accuracy: 0.5534 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9100 - accuracy: 0.5497 - val_loss: 0.8969 - val_accuracy: 0.5582 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9115 - accuracy: 0.5549 - val_loss: 0.8898 - val_accuracy: 0.5762 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9044 - accuracy: 0.5567 - val_loss: 0.8884 - val_accuracy: 0.5552 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8931 - accuracy: 0.5648 - val_loss: 0.8914 - val_accuracy: 0.5612 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8918 - accuracy: 0.5675 - val_loss: 0.8867 - val_accuracy: 0.5642 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8979 - accuracy: 0.5654 - val_loss: 0.8781 - val_accuracy: 0.5756 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8869 - accuracy: 0.5678 - val_loss: 0.8767 - val_accuracy: 0.5798 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8817 - accuracy: 0.5759 - val_loss: 0.8773 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8871 - accuracy: 0.5731 - val_loss: 0.8739 - val_accuracy: 0.5792 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8792 - accuracy: 0.5777 - val_loss: 0.8723 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8787 - accuracy: 0.5777 - val_loss: 0.8848 - val_accuracy: 0.5762 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8712 - accuracy: 0.5834 - val_loss: 0.8760 - val_accuracy: 0.5954 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8675 - accuracy: 0.5843 - val_loss: 0.8600 - val_accuracy: 0.5978 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8728 - accuracy: 0.5816 - val_loss: 0.8697 - val_accuracy: 0.5726 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8740 - accuracy: 0.5779 - val_loss: 0.8693 - val_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8686 - accuracy: 0.5822 - val_loss: 0.8514 - val_accuracy: 0.5996 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8663 - accuracy: 0.5861 - val_loss: 0.8520 - val_accuracy: 0.5942 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8605 - accuracy: 0.5906 - val_loss: 0.8531 - val_accuracy: 0.6056 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8594 - accuracy: 0.5906 - val_loss: 0.8492 - val_accuracy: 0.6104 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8607 - accuracy: 0.5858 - val_loss: 0.8598 - val_accuracy: 0.5948 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8592 - accuracy: 0.5959 - val_loss: 0.8526 - val_accuracy: 0.6170 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8574 - accuracy: 0.5978 - val_loss: 0.8512 - val_accuracy: 0.6194 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8505 - accuracy: 0.5947 - val_loss: 0.8393 - val_accuracy: 0.6194 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8428 - accuracy: 0.5999 - val_loss: 0.8355 - val_accuracy: 0.6140 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.8421 - accuracy: 0.6047 - val_loss: 0.8275 - val_accuracy: 0.6236 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8397 - accuracy: 0.6038 - val_loss: 0.8415 - val_accuracy: 0.6146 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8409 - accuracy: 0.6040 - val_loss: 0.8362 - val_accuracy: 0.6152 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8400 - accuracy: 0.6038 - val_loss: 0.8351 - val_accuracy: 0.6230 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8384 - accuracy: 0.6107 - val_loss: 0.8328 - val_accuracy: 0.6248 - lr: 2.5000e-04\n",
      "Epoch 39/50\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.8368 - accuracy: 0.6115 - val_loss: 0.8307 - val_accuracy: 0.6248 - lr: 2.5000e-04\n",
      "Epoch 40/50\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.8349 - accuracy: 0.5990 - val_loss: 0.8301 - val_accuracy: 0.6230 - lr: 2.5000e-04\n",
      "Epoch 41/50\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.8270 - accuracy: 0.6112 - val_loss: 0.8291 - val_accuracy: 0.6279 - lr: 1.2500e-04\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8275 - accuracy: 0.6236\n",
      "Fold 3 - Loss: 0.827488362789154, Accuracy: 0.6236494779586792\n",
      "Processing fold 4\n",
      "Epoch 1/50\n",
      "417/417 [==============================] - 8s 10ms/step - loss: 1.0192 - accuracy: 0.4652 - val_loss: 0.9760 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9652 - accuracy: 0.5026 - val_loss: 0.9498 - val_accuracy: 0.5252 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9455 - accuracy: 0.5219 - val_loss: 0.9486 - val_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9315 - accuracy: 0.5332 - val_loss: 0.9404 - val_accuracy: 0.5210 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.9276 - accuracy: 0.5363 - val_loss: 0.9344 - val_accuracy: 0.5318 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9243 - accuracy: 0.5360 - val_loss: 0.9330 - val_accuracy: 0.5402 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9162 - accuracy: 0.5419 - val_loss: 0.9287 - val_accuracy: 0.5450 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9189 - accuracy: 0.5450 - val_loss: 0.9200 - val_accuracy: 0.5594 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9130 - accuracy: 0.5525 - val_loss: 0.9152 - val_accuracy: 0.5474 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9086 - accuracy: 0.5542 - val_loss: 0.9220 - val_accuracy: 0.5396 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9037 - accuracy: 0.5536 - val_loss: 0.9119 - val_accuracy: 0.5498 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9032 - accuracy: 0.5552 - val_loss: 0.9137 - val_accuracy: 0.5582 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8961 - accuracy: 0.5651 - val_loss: 0.9204 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8946 - accuracy: 0.5674 - val_loss: 0.9071 - val_accuracy: 0.5624 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8859 - accuracy: 0.5696 - val_loss: 0.9055 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8878 - accuracy: 0.5695 - val_loss: 0.9045 - val_accuracy: 0.5606 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8856 - accuracy: 0.5719 - val_loss: 0.9073 - val_accuracy: 0.5696 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8829 - accuracy: 0.5776 - val_loss: 0.9030 - val_accuracy: 0.5624 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8813 - accuracy: 0.5720 - val_loss: 0.9060 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8771 - accuracy: 0.5810 - val_loss: 0.8992 - val_accuracy: 0.5618 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8741 - accuracy: 0.5819 - val_loss: 0.8886 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8708 - accuracy: 0.5797 - val_loss: 0.8950 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8698 - accuracy: 0.5843 - val_loss: 0.8886 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8671 - accuracy: 0.5893 - val_loss: 0.8902 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8589 - accuracy: 0.5882 - val_loss: 0.8862 - val_accuracy: 0.5732 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8578 - accuracy: 0.5897 - val_loss: 0.8864 - val_accuracy: 0.5864 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8520 - accuracy: 0.5978 - val_loss: 0.8791 - val_accuracy: 0.5834 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8534 - accuracy: 0.5977 - val_loss: 0.8783 - val_accuracy: 0.5822 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8559 - accuracy: 0.5906 - val_loss: 0.8827 - val_accuracy: 0.5828 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8529 - accuracy: 0.5977 - val_loss: 0.8839 - val_accuracy: 0.5840 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8493 - accuracy: 0.5956 - val_loss: 0.8769 - val_accuracy: 0.5906 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8421 - accuracy: 0.6029 - val_loss: 0.8788 - val_accuracy: 0.5918 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8472 - accuracy: 0.5954 - val_loss: 0.8727 - val_accuracy: 0.5930 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8440 - accuracy: 0.6053 - val_loss: 0.8792 - val_accuracy: 0.5876 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8421 - accuracy: 0.6088 - val_loss: 0.8763 - val_accuracy: 0.5894 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8434 - accuracy: 0.6068 - val_loss: 0.8762 - val_accuracy: 0.5876 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8354 - accuracy: 0.6094 - val_loss: 0.8739 - val_accuracy: 0.5936 - lr: 2.5000e-04\n",
      "Epoch 38/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8421 - accuracy: 0.6038 - val_loss: 0.8722 - val_accuracy: 0.5954 - lr: 2.5000e-04\n",
      "Epoch 39/50\n",
      "417/417 [==============================] - 1s 4ms/step - loss: 0.8355 - accuracy: 0.6100 - val_loss: 0.8731 - val_accuracy: 0.5948 - lr: 2.5000e-04\n",
      "Epoch 40/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8387 - accuracy: 0.5995 - val_loss: 0.8715 - val_accuracy: 0.5966 - lr: 2.5000e-04\n",
      "Epoch 41/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8369 - accuracy: 0.6128 - val_loss: 0.8686 - val_accuracy: 0.6038 - lr: 2.5000e-04\n",
      "Epoch 42/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8354 - accuracy: 0.6100 - val_loss: 0.8680 - val_accuracy: 0.5990 - lr: 2.5000e-04\n",
      "Epoch 43/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8392 - accuracy: 0.6037 - val_loss: 0.8711 - val_accuracy: 0.5924 - lr: 2.5000e-04\n",
      "Epoch 44/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8316 - accuracy: 0.6127 - val_loss: 0.8713 - val_accuracy: 0.5966 - lr: 2.5000e-04\n",
      "Epoch 45/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8400 - accuracy: 0.6047 - val_loss: 0.8742 - val_accuracy: 0.5930 - lr: 2.5000e-04\n",
      "Epoch 46/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8289 - accuracy: 0.6101 - val_loss: 0.8695 - val_accuracy: 0.5942 - lr: 1.2500e-04\n",
      "Epoch 47/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8271 - accuracy: 0.6151 - val_loss: 0.8690 - val_accuracy: 0.5954 - lr: 1.2500e-04\n",
      "Epoch 48/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8300 - accuracy: 0.6152 - val_loss: 0.8689 - val_accuracy: 0.5978 - lr: 1.2500e-04\n",
      "Epoch 49/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8301 - accuracy: 0.6190 - val_loss: 0.8680 - val_accuracy: 0.5960 - lr: 6.2500e-05\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.5990\n",
      "Fold 4 - Loss: 0.8679806590080261, Accuracy: 0.599039614200592\n",
      "Processing fold 5\n",
      "Epoch 1/50\n",
      "417/417 [==============================] - 4s 5ms/step - loss: 1.0290 - accuracy: 0.4566 - val_loss: 0.9547 - val_accuracy: 0.4988 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9741 - accuracy: 0.4968 - val_loss: 0.9296 - val_accuracy: 0.5342 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9569 - accuracy: 0.5117 - val_loss: 0.9148 - val_accuracy: 0.5450 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9493 - accuracy: 0.5177 - val_loss: 0.9003 - val_accuracy: 0.5612 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9408 - accuracy: 0.5294 - val_loss: 0.9021 - val_accuracy: 0.5444 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9315 - accuracy: 0.5368 - val_loss: 0.9016 - val_accuracy: 0.5492 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9223 - accuracy: 0.5401 - val_loss: 0.8892 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9192 - accuracy: 0.5503 - val_loss: 0.8929 - val_accuracy: 0.5618 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9198 - accuracy: 0.5378 - val_loss: 0.8827 - val_accuracy: 0.5564 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9106 - accuracy: 0.5497 - val_loss: 0.8852 - val_accuracy: 0.5492 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9096 - accuracy: 0.5545 - val_loss: 0.8843 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9107 - accuracy: 0.5512 - val_loss: 0.8806 - val_accuracy: 0.5606 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9046 - accuracy: 0.5570 - val_loss: 0.8736 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.9006 - accuracy: 0.5614 - val_loss: 0.8729 - val_accuracy: 0.5828 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.9000 - accuracy: 0.5605 - val_loss: 0.8722 - val_accuracy: 0.5888 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8997 - accuracy: 0.5636 - val_loss: 0.8648 - val_accuracy: 0.5768 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8950 - accuracy: 0.5648 - val_loss: 0.8701 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8911 - accuracy: 0.5690 - val_loss: 0.8630 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8850 - accuracy: 0.5690 - val_loss: 0.8549 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8886 - accuracy: 0.5677 - val_loss: 0.8567 - val_accuracy: 0.5924 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8807 - accuracy: 0.5779 - val_loss: 0.8575 - val_accuracy: 0.5966 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8849 - accuracy: 0.5714 - val_loss: 0.8496 - val_accuracy: 0.5858 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8751 - accuracy: 0.5822 - val_loss: 0.8554 - val_accuracy: 0.5912 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8706 - accuracy: 0.5852 - val_loss: 0.8538 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8796 - accuracy: 0.5779 - val_loss: 0.8441 - val_accuracy: 0.5864 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8726 - accuracy: 0.5797 - val_loss: 0.8422 - val_accuracy: 0.6026 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8680 - accuracy: 0.5800 - val_loss: 0.8478 - val_accuracy: 0.5822 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8614 - accuracy: 0.5941 - val_loss: 0.8356 - val_accuracy: 0.6098 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8642 - accuracy: 0.5926 - val_loss: 0.8397 - val_accuracy: 0.6068 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8635 - accuracy: 0.5962 - val_loss: 0.8337 - val_accuracy: 0.6104 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8613 - accuracy: 0.5887 - val_loss: 0.8333 - val_accuracy: 0.6026 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8555 - accuracy: 0.5920 - val_loss: 0.8349 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8505 - accuracy: 0.5971 - val_loss: 0.8299 - val_accuracy: 0.6098 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8568 - accuracy: 0.5993 - val_loss: 0.8294 - val_accuracy: 0.6098 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8485 - accuracy: 0.5986 - val_loss: 0.8265 - val_accuracy: 0.6104 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8551 - accuracy: 0.5972 - val_loss: 0.8323 - val_accuracy: 0.6158 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8504 - accuracy: 0.6001 - val_loss: 0.8303 - val_accuracy: 0.6122 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8556 - accuracy: 0.5992 - val_loss: 0.8246 - val_accuracy: 0.6080 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8502 - accuracy: 0.5971 - val_loss: 0.8215 - val_accuracy: 0.6188 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8497 - accuracy: 0.5971 - val_loss: 0.8335 - val_accuracy: 0.6170 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8434 - accuracy: 0.6043 - val_loss: 0.8285 - val_accuracy: 0.6242 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8434 - accuracy: 0.5965 - val_loss: 0.8263 - val_accuracy: 0.6122 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8377 - accuracy: 0.6071 - val_loss: 0.8171 - val_accuracy: 0.6110 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8336 - accuracy: 0.6095 - val_loss: 0.8145 - val_accuracy: 0.6327 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8306 - accuracy: 0.6148 - val_loss: 0.8170 - val_accuracy: 0.6255 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8351 - accuracy: 0.6115 - val_loss: 0.8177 - val_accuracy: 0.6152 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8297 - accuracy: 0.6134 - val_loss: 0.8127 - val_accuracy: 0.6279 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "417/417 [==============================] - 1s 4ms/step - loss: 0.8323 - accuracy: 0.6109 - val_loss: 0.8134 - val_accuracy: 0.6152 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.8296 - accuracy: 0.6121 - val_loss: 0.8098 - val_accuracy: 0.6206 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.8293 - accuracy: 0.6155 - val_loss: 0.8071 - val_accuracy: 0.6182 - lr: 5.0000e-04\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8071 - accuracy: 0.6182\n",
      "Fold 5 - Loss: 0.8070738315582275, Accuracy: 0.6182472705841064\n",
      "Average Accuracy across all folds: 0.6101788759231568\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(r\"D:\\Github portfolio\\Hemophilia\\Hemophilia-Severity-Predictor\\datasets\\resampled_data_adasyn2.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=['Severity'])\n",
    "y = df['Severity']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(X_scaled, y_encoded):\n",
    "    print(f\"Processing fold {fold}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_val = y_one_hot[train_index], y_one_hot[val_index]\n",
    "    \n",
    "    # Reshape for RNN\n",
    "    X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_val_rnn = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "    \n",
    "    # Define the RNN model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(SimpleRNN(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_rnn, y_train, epochs=50, batch_size=16, validation_data=(X_val_rnn, y_val),\n",
    "                        callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_val_rnn, y_val)\n",
    "    print(f'Fold {fold} - Loss: {loss}, Accuracy: {accuracy}')\n",
    "    \n",
    "    # Store the accuracy of this fold\n",
    "    fold_accuracies.append(accuracy)\n",
    "    \n",
    "    # Increment fold counter\n",
    "    fold += 1\n",
    "\n",
    "    # Clear the model from memory\n",
    "    K.clear_session()\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f'Average Accuracy across all folds: {average_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
